+++
title = "ASR in Action: Meet Colombus, Your AI Video Assistant"
date = "2025-02-18T09:00:00-05:00"
#dateFormat = "2006-01-02" # This value can be configured for per-post date formatting
author = "Diego Garcia"
authorTwitter = "" #do not include @
cover = "img/006.png"
tags = ["ASR", "LLM", "Gradio"]
keywords = ["ASR", "LLM", "Gradio"]
description = "Colombus, an AI-powered assistant that enhances how users interact with YouTube videos. By combining Automatic Speech Recognition (ASR) and a Large Language Model (LLM), Colombus can transcribe, summarize, and answer questions about YouTube videos."
showFullContent = false
readingTime = true
hideComments = true
+++

We‚Äôve all been there, clicking through endless YouTube videos, scrubbing back and forth to find the right moment, or trying to recall what was said five minutes ago. It‚Äôs frustrating. That‚Äôs when I thought, Wouldn‚Äôt it be great if I had an assistant that could help me navigate video content effortlessly?

## What Makes Colombus Special
Here‚Äôs what I found interesting about Colombus, my AI-powered video assistant:

- It listens, transcribes, and understands video content. No more endless rewinds.
- It can summarize key points, so you don‚Äôt have to sit through the whole video if you just need the highlights.
- If you have a specific question about the video, it finds the answer instantly. No need to scroll through comments or rely on vague timestamps.

## How It Works
1. The Listener
   First, Colombus uses Automatic Speech Recognition (ASR) to transcribe the video‚Äôs audio. This creates a searchable text version of the content.

2. The Thinker
   Next, it processes the transcript using a Large Language Model (LLM) to extract key insights, summarize the content, or answer specific questions. It‚Äôs almost like it‚Äôs saying, ‚ÄúHere‚Äôs what I heard, and here‚Äôs what‚Äôs important!‚Äù

3. The Responder
   Finally, it presents the information in a clean, easy-to-read format. Whether you want a full transcript, a short summary, or quick answers, Colombus delivers.

## Watch Colombus in Action!
I‚Äôm also putting together a demo so you can see Colombus work‚Äîtranscribing, summarizing, and responding to queries in real time.

{{< youtube WyYV0tILzu0 >}}

## Wrapping Up
An AI-powered assistant like Colombus makes interacting with video content smoother and more efficient. It‚Äôs like having a personal note-taker and researcher built into YouTube. Of course, there‚Äôs still room for improvement‚Äîespecially in handling noisy and lengthy audio, overlapping speakers, among other obstacles.

This was a fun experiment, and I see a lot of potential in refining Colombus further. If you want to check out the implementation or contribute, you can find the code in my GitHub repo: <br>
   üîó [GitHub Repo](https://github.com/dgarciarieckhof/media.alchemy)


For those interested in learning more about ASR, LLMs, and AI-powered assistants, here are some great resources:

- [Whisper by OpenAI](https://openai.com/index/whisper/): An open-source automatic speech recognition (ASR) system developed by OpenAI, capable of transcribing and translating multiple languages.
- [CTC Alignment](https://pytorch.org/audio/stable/tutorials/forced_alignment_tutorial.html): Connectionist Temporal Classification (CTC) is a training algorithm used for sequence-to-sequence problems, particularly in speech recognition, to align input sequences (like audio) with output labels (like text).
- [Speaker Diarization](https://docs.nvidia.com/nemo-framework/user-guide/24.09/nemotoolkit/asr/speaker_diarization/intro.html): The process of partitioning an audio stream into segments according to the speaker's identity, answering the question "who spoke when."
- [LLM-Powered Chatbots](https://arxiv.org/abs/2406.16937): Chatbots enhanced by Large Language Models (LLMs) can understand and generate human-like text, enabling more natural and context-aware interactions.