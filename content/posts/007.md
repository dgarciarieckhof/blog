+++
title = "DeepSeek: What's Behind the Whale's Numbers?"
date = "2025-03-04T09:00:00-05:00"
#dateFormat = "2006-01-02" # This value can be configured for per-post date formatting
author = "Diego Garcia"
authorTwitter = "" #do not include @
cover = "img/007.png"
tags = ["AI", "Economics"]
keywords = ["AI", "Economics"]
description = "Exploring the economic aspects of DeepSeek, its theoretical margin, and two key sensitivity analyses that help us better understand how different factors influence daily profitability."
math = "katex"
showFullContent = false
readingTime = true
hideComments = true
+++

## DeepSeek
DeepSeek is a Chinese artificial intelligence platform similar to OpenAI or Anthropic, offering two main models:

### **DeepSeek-V3 (deepseek-chat)**  
**Input token cost:**  
- Cache hit: $0.07 per million tokens.  
- Cache miss: $0.27 per million tokens.  

**Output token cost:**  
- $1.10 per million tokens.  

### **DeepSeek-R1 (deepseek-reasoner)**  
**Input token cost:**  
- Cache hit: $0.14 per million tokens.  
- Cache miss: $0.55 per million tokens.  

**Output token cost:**  
- $2.19 per million tokens (including Chain-of-Thought or CoT tokens).  

Both models operate with a context length of up to 64K tokens and use a caching architecture that differentiates between cache hits and cache misses, directly impacting costs and inference speed.

## Infrastructure Costs  
DeepSeek uses nodes equipped with H800 GPUs, where each node consists of 8 GPUs. With an estimated cost of $2 per GPU per hour, the daily operating cost is approximately $87,072 (based on an average of 226.75 active nodes over 24 hours).

## Key Statistics (on a Typical Day)  
- **Input tokens:** 608 billion (with a 56.3% cache hit rate).  
- **Output tokens:** 168 billion.  
- **Daily cost:** ~$87,072.  
- **Theoretical daily revenue (if all tokens were charged at DeepSeek-R1 rates):** ~$562,027.  
- **Theoretical margin:** 545%.  

> **Note:** This theoretical scenario is just a reference point. In practice, DeepSeek-V3 has lower rates, nighttime discounts exist, and not all users pay, as some interfaces (such as the web version or the app) may offer free access.

## Factors Affecting Profitability  
### **1. Model Distribution**  
The balance of users between DeepSeek-V3 and DeepSeek-R1 directly impacts profitability. If more users choose R1, revenue per token will be higher, but resource consumption will also increase, potentially affecting operating costs.
### **2. Percentage of Paying Users**  
Only a fraction of the user base is willing to pay. If this percentage is low, revenues can drop significantly, even if the total token volume is high.
### **3. Cache Hit Ratio**  
A higher cache hit ratio reduces the cost per token but also decreases revenue per billed token. This balance is key to optimizing profitability without sacrificing operational efficiency.
### **4. Peak Hours vs. Nighttime Discounts**  
DeepSeek applies different pricing based on time of day. During off-peak hours (UTC 16:30–00:30), discounts of up to 75% apply, affecting the average revenue.
### **5. Output Tokens and CoT in R1**  
The DeepSeek-R1 model charges for every output token, including those generated during the reasoning process (Chain-of-Thought). If the output is extensive, the revenue per request can increase significantly.

---

## Sensitivity Analysis: Two Perspectives  
### **1. Variation in User Base Size and Percentage of Paying Users**  
This analysis evaluates how profitability changes by modifying:  

- The user base size (user base multiplier), scaling the total token volume (e.g., from 0.5x to 1.5x of the base scenario).  
- The percentage of paying users, ranging from 0% to 100%.  

For each combination, the profit margin is calculated using the formula:  

$$
\text{Profit Margin} = \frac{\text{Revenue} - \text{Costs}}{\text{Costs}}
$$

The results are represented using a heatmap, identifying the breakeven region marked with “+” (where revenue covers costs) and the profit zones (to the right of the dotted line).

![1st sensitivy analysis|](https://dgarciarieckhof.github.io/blog/img/007_1.png)

### **2. Distribution Between DeepSeek-R1 and DeepSeek-V3 for Paying Users**  
This analysis examines the impact of the distribution of paid requests between the two models:
- **R1 Fraction:** The percentage of paying user requests that use DeepSeek-R1 (with the rest using DeepSeek-V3).  

The combined revenue is calculated with the following equation:

$$
\text{Revenue} = \text{Pay Fraction} \times \left[ \text{R1 Fraction} \times \text{Revenue}_{R1} + \left(1 - \text{R1 Fraction}\right) \times \text{Revenue}_{V3} \right]
$$

This analysis helps visualize how profitability varies based on user preferences for each model, identifying the breakeven point and the sensitivity of profitability to changes in request distribution.

![2nd sensitivy analysis|](https://dgarciarieckhof.github.io/blog/img/007_2.png)

---

## Conclusions and Final Thoughts  
This analysis shows that while DeepSeek has high revenue potential, final profitability depends on multiple factors:

- The proportion of paying users is crucial for revenues to exceed fixed costs.  
- The balance between DeepSeek-R1 and V3 significantly impacts profitability: R1 generates more revenue per token but at a higher cost.  
- Factors such as cache hit ratio and nighttime discounts affect the average revenue per token.  

**Final Note:** This analysis focuses on two key variables, but many others could influence profitability. If you want to explore further, check out DeepSeek’s technical articles published during its Open Source Week.

- [FlashMLA](https://github.com/deepseek-ai/FlashMLA): Efficient MLA decoding kernel for Hopper GPUs.
- [DeepEP](https://github.com/deepseek-ai/DeepEP): Communication library for Mixture-of-Experts models.
- [DeepGEMM](https://github.com/deepseek-ai/DeepGEMM): Optimized General Matrix Multiplication library.
- [Optimized Parallelism Strategies](https://github.com/deepseek-ai/DualPipe): Framework for optimizing parallelism in distributed deep learning.
- [Fire-Flyer File System (3FS)](https://github.com/deepseek-ai/3FS): Distributed file system optimized for machine learning workflows.
- [DeepSeek-V3/R1 Inference System](https://github.com/deepseek-ai/profile-data): Large-scale inference system using cross-node Expert Parallelism.
